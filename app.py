import os
from datetime import timedelta

import numpy as np
import pandas as pd
import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import joblib


# =========================
# Config
# =========================
st.set_page_config(page_title="IBOV Signal ‚Äî Sistema Preditivo", layout="wide")

DEFAULT_CSV = "Dados Ibovespa (2).csv"
MODEL_PATH = "modelo_catboost.pkl"
SCALER_PATH = "scaler_minmax.pkl"


# =========================
# M√âTRICAS FIXAS (DO COLAB) ‚Äî SEM RETREINO
# =========================
METRICAS_COLAB = {
    "modelo": "CatBoostClassifier (treinado no Colab / Fase 2)",
    "janela_validacao": "Holdout temporal: √∫ltimos 30 registros como teste",
    "cv_f1_mean": 0.531,
    "cv_f1_pm": 0.083,
    "acc_train": 0.8203,
    "acc_test": 0.8000,
    "overfit": 0.0203,
    "cm": [[13, 3],
           [3, 11]],
    "report": """precision    recall  f1-score   support

0       0.81      0.81      0.81        16
1       0.79      0.79      0.79        14

accuracy                           0.80        30
macro avg       0.80      0.80      0.80        30
weighted avg    0.80      0.80      0.80        30"""
}


# =========================
# Fun√ß√µes do Colab
# =========================
def volume_to_float(value):
    if isinstance(value, str):
        value = value.strip().upper()
        factor = {"K": 1e3, "M": 1e6, "B": 1e9}
        suffix = value[-1]
        multiplier = factor.get(suffix, 1)
        value = value[:-1] if suffix in factor else value
        try:
            return float(value.replace(".", "").replace(",", ".")) * multiplier
        except:
            return np.nan
    return np.nan


def calculate_rsi(prices, window=14):
    changes = prices.diff()
    gains = changes.clip(lower=0)
    losses = -changes.clip(upper=0)
    avg_gain = gains.ewm(alpha=1 / window, adjust=False).mean()
    avg_loss = losses.ewm(alpha=1 / window, adjust=False).mean()
    rs = avg_gain / avg_loss
    return 100 - (100 / (1 + rs))


def macd_components(prices, short=12, long=26, signal=9):
    short_ema = prices.ewm(span=short, adjust=False).mean()
    long_ema = prices.ewm(span=long, adjust=False).mean()
    macd = short_ema - long_ema
    signal_line = macd.ewm(span=signal, adjust=False).mean()
    histogram = macd - signal_line
    return macd, signal_line, histogram


def obv_series(data):
    obv = [0]
    for i in range(1, len(data)):
        if data["√öltimo"].iat[i] > data["√öltimo"].iat[i - 1]:
            obv.append(obv[-1] + data["Vol."].iat[i])
        elif data["√öltimo"].iat[i] < data["√öltimo"].iat[i - 1]:
            obv.append(obv[-1] - data["Vol."].iat[i])
        else:
            obv.append(obv[-1])
    return obv


def zscore_roll(s: pd.Series, w: int = 20) -> pd.Series:
    m = s.rolling(w, min_periods=w).mean()
    sd = s.rolling(w, min_periods=w).std()
    return (s - m) / sd


def correcao_escala_por_vizinhanca(df: pd.DataFrame) -> pd.DataFrame:
    """
    Patch id√™ntico ao seu Colab para corrigir '√öltimo' quando vem 10x/100x/1000x menor.
    Deve rodar ANTES das features, sen√£o o gr√°fico fica 'pente' e as features ficam distorcidas.
    """
    df = df.copy()

    df["Data"] = pd.to_datetime(df["Data"], errors="coerce")
    df["√öltimo"] = pd.to_numeric(df["√öltimo"], errors="coerce")

    df = df.dropna(subset=["Data", "√öltimo"]).sort_values("Data").reset_index(drop=True)

    for i in range(1, len(df)):
        prev = df.loc[i - 1, "√öltimo"]
        curr = df.loc[i, "√öltimo"]

        if curr < prev * 0.2:
            for fator in [10, 100, 1000]:
                if prev * 0.7 < curr * fator < prev * 1.3:
                    df.loc[i, "√öltimo"] = curr * fator
                    break

    return df


def carregar_dados(caminho_csv):
    """
    Pipeline do Colab + patch de corre√ß√£o de escala (para evitar gr√°fico 'pente').
    """
    # 1) Ler e padronizar
    df = pd.read_csv(caminho_csv)
    df.columns = df.columns.str.strip()
    df["Data"] = pd.to_datetime(df["Data"], format="%d.%m.%Y", errors="coerce")
    df = df.sort_values("Data").dropna(subset=["Data"])

    # 2) Converter volume e pre√ßos (locale BR -> float)
    df["Vol."] = df["Vol."].apply(volume_to_float)

    for coluna in ["√öltimo", "Abertura", "M√°xima", "M√≠nima"]:
        df[coluna] = (
            df[coluna].astype(str)
            .str.replace(".", "", regex=False)
            .str.replace(",", ".", regex=False)
        )
        df[coluna] = pd.to_numeric(df[coluna], errors="coerce")

    # ===== PATCH DO COLAB (IMPORTANTE) =====
    df = correcao_escala_por_vizinhanca(df)
    df = df.sort_values("Data").reset_index(drop=True)

    # 3) Features base
    df["var_pct"] = df["√öltimo"].pct_change()
    for dias in [3, 7, 14, 21, 30]:
        df[f"mm_{dias}"] = df["√öltimo"].rolling(dias, min_periods=dias).mean()
    for dias in [5, 10, 20]:
        df[f"vol_{dias}"] = df["√öltimo"].rolling(dias, min_periods=dias).std()

    df["desvio_mm3"] = df["√öltimo"] - df["mm_3"]
    df["dia"] = df["Data"].dt.weekday
    df["rsi"] = calculate_rsi(df["√öltimo"])
    macd, sinal, hist = macd_components(df["√öltimo"])
    df["macd"], df["sinal_macd"], df["hist_macd"] = macd, sinal, hist

    # Bandas de Bollinger (20) e largura relativa
    bb_media = df["√öltimo"].rolling(20, min_periods=20).mean()
    bb_std = df["√öltimo"].rolling(20, min_periods=20).std()
    df["bb_media"] = bb_media
    df["bb_std"] = bb_std
    df["bb_sup"] = bb_media + 2 * bb_std
    df["bb_inf"] = bb_media - 2 * bb_std
    df["bb_largura"] = (df["bb_sup"] - df["bb_inf"]) / bb_media

    # ATR (14)
    tr1 = df["M√°xima"] - df["M√≠nima"]
    tr2 = (df["M√°xima"] - df["√öltimo"].shift(1)).abs()
    tr3 = (df["M√≠nima"] - df["√öltimo"].shift(1)).abs()
    df["TR"] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    df["ATR"] = df["TR"].rolling(14, min_periods=14).mean()

    # OBV e Alvo
    df["obv"] = obv_series(df)
    df["Alvo"] = (df["√öltimo"].shift(-1) > df["√öltimo"]).astype("int8")
    df = df.iloc[:-1].copy()

    # 4) Transforma√ß√µes mais estacion√°rias
    df["ret_1d"] = df["√öltimo"].pct_change()
    df["log_ret"] = np.log(df["√öltimo"]).diff()
    df["ret_5d"] = df["√öltimo"].pct_change(5)
    df["rv_20"] = df["ret_1d"].rolling(20, min_periods=20).std()

    df["atr_pct"] = df["ATR"] / df["√öltimo"]
    df["desvio_mm3_pct"] = (df["desvio_mm3"] / df["mm_3"]).replace([np.inf, -np.inf], np.nan)

    df["vol_log"] = np.log(df["Vol."].clip(lower=1))
    # ‚úÖ CORRE√á√ÉO DO BUG (-npinf -> -np.inf)
    df["vol_ret"] = df["Vol."].pct_change().replace([np.inf, -np.inf], np.nan)

    df["obv_diff"] = pd.Series(df["obv"]).diff()

    df["z_close_20"] = zscore_roll(df["√öltimo"], 20)
    df["z_rsi_20"] = zscore_roll(df["rsi"], 20)
    df["z_macd_20"] = zscore_roll(df["macd"], 20)

    # 5) Limpeza de NaN com base nas features que realmente iremos usar
    features_sugeridas = [
        "ret_1d", "log_ret", "ret_5d", "rv_20",
        "atr_pct", "bb_largura", "desvio_mm3_pct",
        "vol_log", "vol_ret", "obv_diff",
        "rsi", "macd", "sinal_macd", "hist_macd",
        "dia", "z_close_20", "z_rsi_20", "z_macd_20"
    ]
    df = df.dropna(subset=features_sugeridas + ["Alvo"]).copy()
    df.attrs["features_sugeridas"] = features_sugeridas
    return df


# =========================
# Cache de carga
# =========================
@st.cache_resource
def load_model_and_scaler():
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"N√£o encontrei `{MODEL_PATH}` no reposit√≥rio.")
    if not os.path.exists(SCALER_PATH):
        raise FileNotFoundError(f"N√£o encontrei `{SCALER_PATH}` no reposit√≥rio.")
    model = joblib.load(MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)
    return model, scaler


@st.cache_data
def load_df_and_features(csv_path):
    df = carregar_dados(csv_path)
    features = df.attrs["features_sugeridas"]
    return df, features


# =========================
# Gr√°ficos
# =========================
def make_signal_chart(df_plot, pred, proba, threshold, title):
    price_vals = df_plot["√öltimo"].astype(float).values
    dates = df_plot["Data"]

    fig = make_subplots(
        rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.08,
        row_heights=[0.68, 0.32],
        subplot_titles=("Pre√ßo (corrigido) + Sinal", "Probabilidade P(ALTA)")
    )

    fig.add_trace(
        go.Scatter(x=dates, y=price_vals, mode="lines", name="Pre√ßo (√öltimo)"),
        row=1, col=1
    )

    fig.add_trace(
        go.Scatter(
            x=dates, y=np.where(pred == 1, price_vals, np.nan),
            mode="markers", name="ALTA", marker=dict(size=9, symbol="triangle-up")
        ),
        row=1, col=1
    )
    fig.add_trace(
        go.Scatter(
            x=dates, y=np.where(pred == 0, price_vals, np.nan),
            mode="markers", name="BAIXA", marker=dict(size=8, symbol="triangle-down")
        ),
        row=1, col=1
    )

    fig.add_trace(
        go.Scatter(x=dates, y=proba, mode="lines", fill="tozeroy", name="P(ALTA)"),
        row=2, col=1
    )
    fig.add_hline(
        y=threshold, line_dash="dash", line_width=2,
        annotation_text=f"threshold={threshold:.2f}",
        row=2, col=1
    )

    fig.update_layout(
        height=650,
        margin=dict(l=10, r=10, t=60, b=10),
        legend=dict(orientation="h"),
        title=title,
    )
    fig.update_yaxes(title_text="Pre√ßo", row=1, col=1)
    fig.update_yaxes(title_text="P(ALTA)", range=[0, 1], row=2, col=1)
    fig.update_xaxes(rangeslider_visible=True)
    return fig


def predict_proba_batch(model, scaler, X, threshold):
    Xs = scaler.transform(X)
    if hasattr(model, "predict_proba"):
        proba = model.predict_proba(Xs)[:, 1]
    else:
        proba = model.predict(Xs).astype(float)
    pred = (proba >= threshold).astype(int)
    return pred, proba


def plot_confusion_matrix(cm, labels=("Queda (0)", "Alta (1)")):
    cm = np.array(cm, dtype=int)
    x = [f"Prev: {labels[0]}", f"Prev: {labels[1]}"]
    y = [f"Real: {labels[0]}", f"Real: {labels[1]}"]

    fig = go.Figure(
        data=go.Heatmap(
            z=cm,
            x=x,
            y=y,
            text=cm,
            texttemplate="%{text}",
            hovertemplate="",
        )
    )
    fig.update_layout(
        title="Matriz de Confus√£o (valores do Colab)",
        height=420,
        margin=dict(l=10, r=10, t=50, b=10)
    )
    return fig


# =========================
# App
# =========================
st.title("üìà IBOV Signal ‚Äî Sistema Preditivo (modelo do Colab, sem re-treino)")

with st.sidebar:
    st.header("Config")
    threshold = st.slider("Threshold para ALTA", 0.30, 0.70, 0.50, 0.01)
    view_n = st.slider("Janela do gr√°fico (√∫ltimos N)", 60, 1500, 400, 20)
    st.caption("Patch de escala do `√öltimo` aplicado (corrige gr√°fico 'pente').")

# Checar CSV no repo
if not os.path.exists(DEFAULT_CSV):
    st.error(
        f"N√£o encontrei `{DEFAULT_CSV}` no reposit√≥rio. "
        "Suba esse CSV junto com o app.py para o Streamlit n√£o pedir upload."
    )
    st.stop()

# Carregar modelo/scaler
try:
    model, scaler = load_model_and_scaler()
except Exception as e:
    st.error(str(e))
    st.stop()

# Carregar dados com patch
df, features = load_df_and_features(DEFAULT_CSV)

# Tabs
tab_produto, tab_futuro, tab_diag = st.tabs(
    ["üß† Produto", "üîÆ Simula√ß√£o futura (data alvo)", "üîé Diagn√≥stico (m√©tricas)"]
)

with tab_produto:
    st.subheader("Produto: selecione uma data e obtenha a tend√™ncia do dia seguinte")

    date_options = df["Data"].dt.date.tolist()
    selected_date = st.selectbox("Data (hist√≥rico)", options=date_options, index=len(date_options) - 1)

    idx_list = df.index[df["Data"].dt.date == selected_date]
    idx = int(idx_list[0])

    X_sel = df.loc[[idx], features].values
    pred_sel, proba_sel = predict_proba_batch(model, scaler, X_sel, threshold)
    y = int(pred_sel[0])
    p = float(proba_sel[0])

    if y == 1:
        st.success(f"üìà Tend√™ncia prevista (dia seguinte): **ALTA** ‚Äî P(ALTA)={p:.2%}")
    else:
        st.warning(f"üìâ Tend√™ncia prevista (dia seguinte): **BAIXA** ‚Äî P(ALTA)={p:.2%}")

    st.write("Linha do dia selecionado (j√° com `√öltimo` corrigido):")
    st.dataframe(
        df.loc[[idx], ["Data", "√öltimo", "Vol.", "rsi", "macd", "bb_largura", "atr_pct", "Alvo"]],
        use_container_width=True
    )

    df_plot = df.tail(int(view_n)).copy()
    X_plot = df_plot[features].values
    pred_plot, proba_plot = predict_proba_batch(model, scaler, X_plot, threshold)

    fig = make_signal_chart(df_plot, pred_plot, proba_plot, threshold, "Hist√≥rico + Sinais do modelo (com corre√ß√£o de escala)")
    st.plotly_chart(fig, use_container_width=True)

with tab_futuro:
    st.subheader("Simula√ß√£o futura para uma DATA ALVO (cen√°rio)")
    st.write(
        "Como n√£o existe pre√ßo real futuro no dataset, aqui √© uma **simula√ß√£o de cen√°rio**: "
        "voc√™ define um retorno di√°rio e o modelo classifica ALTA/BAIXA para cada dia simulado."
    )

    last_date = df["Data"].iloc[-1]
    last_price = float(df["√öltimo"].iloc[-1])
    last_vol = float(df["Vol."].iloc[-1]) if pd.notna(df["Vol."].iloc[-1]) else 0.0

    st.info(f"√öltimo ponto: {last_date.date()} ‚Äî √öltimo={last_price:,.2f}".replace(",", "X").replace(".", ",").replace("X", "."))

    st.markdown("### üéØ Escolha a data alvo (quantos dias √† frente)")
    max_days = 120
    dias_a_frente = st.slider("Dias √† frente", 1, max_days, 30, 1)
    data_alvo = last_date + timedelta(days=int(dias_a_frente))
    st.write(f"üìÖ Data alvo: **{data_alvo.date()}**")

    st.markdown("### üìå Defina o cen√°rio")
    mode = st.selectbox("Cen√°rio", ["Constante", "Constante + Ru√≠do", "Aleat√≥rio (volatilidade)"])
    if mode == "Constante":
        mu = st.number_input("Retorno di√°rio (%)", value=0.20, step=0.05) / 100.0
        sigma = 0.0
    elif mode == "Constante + Ru√≠do":
        mu = st.number_input("Retorno m√©dio di√°rio (%)", value=0.15, step=0.05) / 100.0
        sigma = st.number_input("Ru√≠do di√°rio (%)", value=0.30, step=0.05) / 100.0
    else:
        mu = st.number_input("Retorno m√©dio di√°rio (%)", value=0.05, step=0.05) / 100.0
        sigma = st.number_input("Volatilidade di√°ria (%)", value=0.80, step=0.05) / 100.0

    seed = st.number_input("Seed", value=42, step=1)
    np.random.seed(int(seed))

    horizon = int(dias_a_frente)
    future_dates = [last_date + timedelta(days=i) for i in range(1, horizon + 1)]
    rets = np.random.normal(loc=mu, scale=sigma, size=horizon)

    prices = [last_price]
    for r in rets:
        prices.append(prices[-1] * (1.0 + r))
    future_prices = prices[1:]

    base = df[["Data", "Vol.", "√öltimo", "Abertura", "M√°xima", "M√≠nima"]].copy()
    fut = pd.DataFrame({
        "Data": future_dates,
        "Vol.": [last_vol for _ in range(horizon)],
        "√öltimo": future_prices,
        "Abertura": future_prices,
        "M√°xima": [p * 1.002 for p in future_prices],
        "M√≠nima": [p * 0.998 for p in future_prices],
    })

    full = pd.concat([base, fut], ignore_index=True).sort_values("Data").reset_index(drop=True)
    full = correcao_escala_por_vizinhanca(full)

    # Recalcular features no "full"
    full["var_pct"] = full["√öltimo"].pct_change()
    for dias in [3, 7, 14, 21, 30]:
        full[f"mm_{dias}"] = full["√öltimo"].rolling(dias, min_periods=dias).mean()
    for dias in [5, 10, 20]:
        full[f"vol_{dias}"] = full["√öltimo"].rolling(dias, min_periods=dias).std()

    full["desvio_mm3"] = full["√öltimo"] - full["mm_3"]
    full["dia"] = pd.to_datetime(full["Data"]).dt.weekday
    full["rsi"] = calculate_rsi(full["√öltimo"])

    macd, sinal, hist = macd_components(full["√öltimo"])
    full["macd"], full["sinal_macd"], full["hist_macd"] = macd, sinal, hist

    bb_media = full["√öltimo"].rolling(20, min_periods=20).mean()
    bb_std = full["√öltimo"].rolling(20, min_periods=20).std()
    full["bb_media"] = bb_media
    full["bb_std"] = bb_std
    full["bb_sup"] = bb_media + 2 * bb_std
    full["bb_inf"] = bb_media - 2 * bb_std
    full["bb_largura"] = (full["bb_sup"] - full["bb_inf"]) / bb_media

    tr1 = full["M√°xima"] - full["M√≠nima"]
    tr2 = (full["M√°xima"] - full["√öltimo"].shift(1)).abs()
    tr3 = (full["M√≠nima"] - full["√öltimo"].shift(1)).abs()
    full["TR"] = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    full["ATR"] = full["TR"].rolling(14, min_periods=14).mean()

    full["obv"] = obv_series(full)

    full["ret_1d"] = full["√öltimo"].pct_change()
    full["log_ret"] = np.log(full["√öltimo"]).diff()
    full["ret_5d"] = full["√öltimo"].pct_change(5)
    full["rv_20"] = full["ret_1d"].rolling(20, min_periods=20).std()

    full["atr_pct"] = full["ATR"] / full["√öltimo"]
    full["desvio_mm3_pct"] = (full["desvio_mm3"] / full["mm_3"]).replace([np.inf, -np.inf], np.nan)

    full["vol_log"] = np.log(full["Vol."].clip(lower=1))
    full["vol_ret"] = full["Vol."].pct_change().replace([np.inf, -np.inf], np.nan)

    full["obv_diff"] = pd.Series(full["obv"]).diff()

    full["z_close_20"] = zscore_roll(full["√öltimo"], 20)
    full["z_rsi_20"] = zscore_roll(full["rsi"], 20)
    full["z_macd_20"] = zscore_roll(full["macd"], 20)

    future_block = full[full["Data"].isin(future_dates)].copy()
    future_block = future_block.dropna(subset=features)

    if len(future_block) == 0:
        st.error("Sem features suficientes para a data alvo. Aumente o horizonte ou ajuste o cen√°rio.")
        st.stop()

    Xf = future_block[features].values
    pred_f, proba_f = predict_proba_batch(model, scaler, Xf, threshold)

    future_block["P(ALTA)"] = proba_f
    future_block["Sinal"] = np.where(pred_f == 1, "ALTA", "BAIXA")

    # Resultado para a data alvo (√∫ltima linha simulada v√°lida)
    sinal_alvo = int(pred_f[-1])
    proba_alvo = float(proba_f[-1])
    data_real_alvo = pd.to_datetime(future_block["Data"].iloc[-1]).date()

    if sinal_alvo == 1:
        st.success(f"üìà Tend√™ncia prevista para **{data_real_alvo}**: **ALTA** ‚Äî P(ALTA)={proba_alvo:.2%}")
    else:
        st.warning(f"üìâ Tend√™ncia prevista para **{data_real_alvo}**: **BAIXA** ‚Äî P(ALTA)={proba_alvo:.2%}")

    st.dataframe(future_block[["Data", "√öltimo", "P(ALTA)", "Sinal"]], use_container_width=True)

    fig2 = make_signal_chart(
        df_plot=future_block,
        pred=pred_f,
        proba=proba_f,
        threshold=threshold,
        title="Simula√ß√£o futura ‚Äî sinais do modelo (at√© a data alvo)",
    )
    st.plotly_chart(fig2, use_container_width=True)

with tab_diag:
    st.subheader("Painel expl√≠cito de m√©tricas (fixas do Colab ‚Äî sem re-treino)")

    st.caption(f"Modelo: {METRICAS_COLAB['modelo']}")
    st.caption(f"Valida√ß√£o: {METRICAS_COLAB['janela_validacao']}")

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("Acur√°cia Treino", f"{METRICAS_COLAB['acc_train']*100:.2f}%")
    c2.metric("Acur√°cia Teste", f"{METRICAS_COLAB['acc_test']*100:.2f}%")
    c3.metric("Overfitting", f"{METRICAS_COLAB['overfit']*100:.2f}%")
    c4.metric("F1 (CV)", f"{METRICAS_COLAB['cv_f1_mean']:.3f} ¬± {METRICAS_COLAB['cv_f1_pm']:.3f}")

    st.divider()

    cm = METRICAS_COLAB["cm"]
    cm_df = pd.DataFrame(
        cm,
        index=["Real: Queda (0)", "Real: Alta (1)"],
        columns=["Prev: Queda (0)", "Prev: Alta (1)"]
    )

    colA, colB = st.columns([1, 1.2])
    with colA:
        st.write("Matriz de confus√£o (tabela):")
        st.dataframe(cm_df, use_container_width=True)

    with colB:
        st.write("Matriz de confus√£o (gr√°fico):")
        st.plotly_chart(plot_confusion_matrix(cm), use_container_width=True)

    st.divider()

    st.write("Classification report (do Colab):")
    st.code(METRICAS_COLAB["report"])

    st.divider()

    st.write("Diagn√≥stico do dataset carregado (para auditoria):")
    d1, d2, d3 = st.columns(3)
    d1.metric("Linhas v√°lidas (features)", len(df))
    d2.metric("Data inicial", str(df["Data"].iloc[0].date()))
    d3.metric("Data final", str(df["Data"].iloc[-1].date()))

    st.write("Resumo do `√öltimo` (corrigido):")
    st.write(df["√öltimo"].describe())

    st.write("√öltimos 10 pontos (Data, √öltimo):")
    st.dataframe(df[["Data", "√öltimo"]].tail(10), use_container_width=True)

